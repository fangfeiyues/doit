1.大体来说Mysql可以分为Server层和存储引擎两层。
Server: 
连接器 -- 管理连接权限验证 
分析器 -- 词法分析语法分析,
优化器 -- 执行计划生成，索引选择
执行器 -- 操作引擎，返回结果
存储引擎 -- 存储数据提供读写接口
rows_examined

【SQL执行更新】
redolog(InnoDB): 保证crash-safe能力；物理日志；循环写不具备持久化能力；记录了做了什么改动
binlog(Server归档日志): 归档；逻辑日志；每次事物的逻辑日志 都会持久化到磁盘。statement- 记录sql。row- 记录改动前后行的内容以及详细的sql如主键ID
两者日志保存的顺序是redolog-binlog，它们在写的过程中必须保证事务性不然在日志恢复数据的时候就会造成与原库不一致
WAL：先写日志在写磁盘(先写粉板再写账本)，具体的就是一条记录来的时候会先下redo log并更新内存，InnoDB引擎在合适的时候更新到磁盘

【事务隔离性】
事务的ACID: 原子性一致性隔离性持久性
读未提交：可以读取到其他事务未提交的内容，可能导致脏读(读到未提交的数据)
读提交：只能读取到其他事务提交的内容，可能导致不可重复读(两次查询之间有了一次更新)。一般数据库的默认方式但非mysql
可重复读：同一个事务在多实例并发读取数据时可以看到同样的数据，可能导致幻读
串型化：强制事务排序，使之不能相互冲突解决幻读
长事务：set autocommit=1

RR级别下事务T启动会创建视图read-view. 
mysql下的两种view: 1. create view ... 创建视图  2.在MVCC时候的一致性视图用于支持RC和RR
每个事务都有一个当前启动还没提交的事务ID数组. 数组中最小值记为低水位 事务ID的最大值加1记为高水位
视图一致性
select..where 是快照读 只能读到事务开始之前提交的row trx_id即低水位的提交事务
事务的可重复读能力是怎么实现的？-- 可重复读的核心就是一致性读；而事务更新的时候只能用当前读，如果当前记录的行锁被占用则等待
RC和RR的区别(视图)：
1.RR只要事务一开始创建视图那么事务后面的查询都会使用这个视图
2.RC每个执行语句都会算出一个新的视图
对于可重复读，查询只承认在事务启动前就已经提交完成的数据；
对于读提交，查询只承认在语句启动前就已经提交完成的数据；

【索引】
InnoDB的索引模型：B+树。每个索引在InnoDB中都对应一颗B+树
主键索引：叶子节点存的是整行数据。也被称为聚簇索引
非主键索引：叶子节点内容是主键的值。也被称为二级索引
采用N叉树的原因：相比于搜索二叉树访问磁盘的次数更少了。1200的数据块树高为4的时候已经有1200的三次方17亿的数据一次访问只要三次访问磁盘

二叉查找树 --> 磁盘I/O  1.每个节点存储多个元素 2.采用N叉树
平衡二叉树 -->
m阶B树 --> 数据都保存在节点里如果某个字段太长容纳的数据量受到限制
1.根节点至少有两个子节点  
2.每个中间节点都包含k-1个元素和k个孩子其中 m/2<= k <=m  
3.每个叶子节点都包含k-1个元素 
4.所有叶子节点都位于同一层
5.每个节点中的元素从小到大排序 节点当中k-1个元素正好是k个节点包含的元素的值域分划
B+树 -->
1.有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据只用来索引所有数据都保存在叶子节点
2.所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针且叶子结点本身依关键字的大小自小而大顺序链接
3.所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素


【普通索引和唯一索引】
两者的性能差异：
change buffer: 在更新操作时如果数据在内存中则直接更新否则将更新数据存放发到change buffer中下次读取直接能。同时也会定期写入磁盘。这样对于唯一索引来说就无法使用了
对于写多读少的业务场景来说，不断的写入缓存change buffer同时不会立即读
merge过程：
	1.从磁盘读入数据到内存
	2.从change buffer找到这个数据页的可能是多个change buffer记录，一次应用
	3.写redo log

redo log & change buffer: 
   redo log主要节省的是随机写的IO磁盘消耗(转成顺序写)，而change buffer主要节省的则是随机读的磁盘消耗。


【表锁&行锁】



【mysql抖动】
内存不足 / redo日志满了 --> flush刷脏，造成短暂不可用


【表数据删除】
delete只是把记录的位置或数据页标记为了"可复用"但是磁盘文件的大小是不会变的
因为B+索引分裂 可能造成的page空洞
重建表，把A的数据重建到B中较少空洞。在mysql5.6 online DDL
alter table t where engine=InnoDB


【count(*)】
MyISAM引擎把表的总行数存在磁盘上了因此执行count(*)的时候效率很高
同一时刻查询 由于多版本并发控制(MVCC)的原因 InnoDB表"应该返回多少"也是不确定的 --> 自己计数
count(*)~~
count(1) -- 每一行不为null 则放个数字"1" >
count(id) -- 拿到每一行的id返回给server  >
count(字段) -- 


【order by】
sort_buffer
select id from t order by rand() limit 3;


【读一行也慢】
1.锁等待  show processlist;
2.等flush  
3.等行锁  


【幻读】
a.幻读指的是一个事务在前后两次当前读查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行
  a1: 在可重复读的隔离级别下普通查询是快照读是不会看到别的事务插入的数据的，幻读只有在当前读(如for update读到所有已经提交的事务)下才会出现
  a2: **这专指插入的行不包括修改之后查询得到的**
b.当前读(补充)
数据一致性
间隙锁next-key lock ~ 可重读读的情况下才会生效 同时也可能导致的死锁
如果把隔离级别设置为读提交 同时binlog_format=row

【一行语句的加锁】
加锁规则：
1.加锁的基本单位是next-key lock
2.查找过程中访问到对象才会加锁
3.优化1--索引上的等值查询 给唯一索引加锁的时候 next-key lock退化为行锁 !!!!!
4.优化2--索引上的等值查询 向右遍历时最后一个值不满足等值条件的时候 next-key lock退化为间隙锁 
 ====> 3.4翻译过来就是等值查询中next-key lock要不成行锁(唯一索引)，要么继续向后遍历且退化的间隙锁

等值查询间隙锁：
update t set d=d+1 where id=7. -- 没有id=7记录 (5,10]->(5,10)
lock in share mode 只锁覆盖索引；for update 会认为你要更新数据会顺便把主键索引上满足条件的索引加上行锁

非唯一索引等值锁：
select id from t where c=5 lock in share mode.  
'lock share in mode'锁覆盖索引

主键索引范围锁：
select * from t where id>=10 and id<11 for update. --next-key lock为(5,10]->10行锁 -->10&(10,15] 
非唯一索引范围锁：
select * from t where c>=10 and c<11 for update. -- 不会退化(5,10]和(10,15]
唯一索引范围锁：

如果sql语句加上limit n 那么在遍历到n条数据之后就不会再向后加锁
死锁：next-key lock是分为两段锁来执行的 先加间隙锁再加行锁
sessionA：1.begin; select id from t where c=10 lock in share mode;  3.insert into values(8,8,8) []
sesisonB：2.update t set d=d+1 where c=10;[先锁(5,10) 再锁10行锁]


【饮鸩止渴】


【Mysql怎么保证数据不丢失】
binlog写入机制：
   每个线程有自己的binlog cache事务执行过程中先把日志写到binlog cache事务提交的时候再把binlog cache提交到binlog文件。
   write是写入到系统的page cache再通过sync写到磁盘。sync_binlog控制写入的时机
redo写入机制：
   redo buffer里面不是每次都持久化但也会持久化innodb_log_buffer_size空间大小到一半的时候或并行事务顺带持久化

[MySQL的高可用]
备份数据延迟：
1.备库所在的机器比主库差
2.备库承担部分读功能压力大；--一主多从；binlog输出到外部系统，让外部系统提供类查询能力
3.大事务，如delete删除过多的数据 
4.备库并行复制能力
解决：
可靠性优先策略：1.
可用性优先策略
   
[备库延迟好几个小时]
备库的并行复制能力满足两点：1.不能更新覆盖 2.同一个事务不能被拆开
按表分配策略
按行分配策略，binlog的模式必须是row(statement)
MySQL5.6-- 按照库并行；
MariaDB-- redo log的组提交；主库上可以并行的事务备库上也一定可以
   

[主库出了问题从库怎么办]   
一主多从 主库出现问题切换到备库的策略
1.基于位点的主备切换 change master
CHANGE MASTER TO 
MASTER_HOST=$host_name 
MASTER_PORT=$port 
MASTER_USER=$user_name 
MASTER_PASSWORD=$password 
MASTER_LOG_FILE=$master_log_name   // 主库的log_file继续同步
MASTER_LOG_POS=$master_log_pos  
2.MySQL5.6 GTID
GTID=source_id:transaction_id 全局事务ID
CHANGE MASTER TO 
MASTER_HOST=$host_name 
MASTER_PORT=$port 
MASTER_USER=$user_name 
MASTER_PASSWORD=$password 
master_auto_position=1 


[MySQL数据查询]
   

   

   
---------------------------------------------------------
共享锁(S锁) select ... lock in share mode: 
排它锁(X锁) select ... for update: 
记录锁：与本身，next-key冲突
间隙锁Gap: 开区间 只与gapII冲突
next-key lock = 间隙锁 + 行锁: 前开后闭
insert_intension lock(gapII): 插入意向锁，只在insert   和Gap或next-key lock冲突
乐观锁：
悲观锁：

MVCC(Multi-Version Concurrency Control)多版本并发控制：获得高并发性能
   “读不加锁，读写不冲突”，对立的就是锁的并发控制不区别当前读和快照读均为当前读即读加读锁写加X锁(Serializable)
在MVCC并发控制中读操作可以分为两类：快照读与当前读
快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁
    如select * where
当前读，读取的是记录的最新版本，并且当前读返回的记录都会加上锁，保证其他事务不会再并发修改这条记录
    如lock in share mode(S锁); for update; insert; update; delete

for update 仅适用于InnoDB存储引擎，且必须在事务区块(BEGIN/COMMIT)中才能生效。
select @@tx_isolation;
select * from information_schema.innodb_locks;  -- 查看锁竞争

-- sync_binlog(binlog): 这个参数是对于MySQL系统来说是至关重要的，他不仅影响到Binlog对MySQL所带来的性能损耗，而且还影响到MySQL中数据的完整性
sync_binlog=0, 当事务提交之后，MySQL不做fsync之类的磁盘同步指令刷新binlog_cache中的信息到磁盘，而让Filesystem自行决定什么时候来做同步，或者cache满了之后才同步到磁盘
sync_binlog=n, 当每进行n次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据强制写入磁盘
当设置为1的时候是最安全但是性能损耗最大的设置因为即使系统Crash，也最多丢失binlog_cache中未完成的一个事务，对实际数据没有任何实质性影响

-- innodb_flush_log_at_trx_commit(redo):
==0, 每次事务提交都只是停留在redo log buffer
==1, 都将redo直接持久化到磁盘
==2, 都只是把redo log写到page cache
InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log中的日志调用write写到文件系统的page cache然后fsync持久化到磁盘

"双1方案"













